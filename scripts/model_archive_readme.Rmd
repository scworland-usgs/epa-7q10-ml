---
title: "Readme for modeling 7Q10s using machine learning"
header-includes: \usepackage{graphicx}
subtitle: "https://doi.org/10.5066/F7CR5S4T"
author: "scworland@usgs.gov"
date: "7/5/2017"
output: 
  pdf_document: 
    toc: yes
    toc_depth: 4
---

```{r setup, echo=F}
knitr::opts_knit$set(root.dir = "~/Documents/Ungaged basins/epa_7q10_ml")
```

## Introduction

This readme file is intended to serve as a navigation guide for the model archive associated with the paper (citation information). The basic file contents and dependencies look like:

\begin{figure}[ht]
\begin{center}
\includegraphics[width=6in]{~/Documents/Ungaged basins/epa_7q10_ml/figures/epa_7q10_ml_scripts.png}
\end{center}
\end{figure}

The arrows should be interpreted as "output dependency flow". The steps should be run in roughly clockwise order. Each primary step can be run directly with "main.R" file via custom R functions that have the same name as the othe R files in the figure above. Solid lines indicate primary functions that are sourced directly within "main.R" file, and the dashed lines indicate secondary functions that are sourced by the primary functions. For example, the "train_ml_models.R" file is sourced and run directly by "main.R", but "train_ml_models.R" is depedent on "bayes_optim_caret.R". The idea behind structuring the model archive in this way is that output dependencies can be traced directly back to the input data csv file titled "lowflow_sc_ga_al_gagesII_2015.csv". The steps from the data file to the output should be completely reproducible^[With the exception of possible stochastic differences in model training. This is discussed in more detail in lower sections] if functions are run in sequential order. The monte_carlo.R script is greyed out because it was dropped from the analysis.

\newpage

## Quick start

Although all the scripts are included in the model archive, most of them need not be run to recreate a bulk of the important results. The quickest way to get started is by opening the "main.R" file and setting up the work environment. This includes installing pacakges and setting the working directory.

\vspace{8pt}

```{r, eval=F}
# Install all packages required for entire analysis. The libraries needed for 
# each function are loaded in the function script. 
install.packages(c("dplyr","reshape2","randomForest","kknn","caret",
                   "xgboost","kernlab","Cubist","glmnet","devtools","AER",
                   "leaps","doMC","ICEbox","geoR"))

# install PUBAD package off of github
devtools::install_github("wfarmer-usgs/PUBAD")

# load libraries needed for main.R script
library(dplyr); library(PUBAD)

# set working directory
setwd("~/set/working/directoy")
```

The next step is to load the csv file and prepare the data as input for the functions. The only packages that are required for this step are `dplyr` and `PUBAD`. 

\vspace{8pt}

```{r, eval=F}
# Load csv file: note, data should be in a "data" folder in working directory
data_full <- read.csv("data/lowflow_sc_ga_al_gagesII_2015.csv",
                      header=T,na.strings = "-999") %>%
  setNames(tolower(names(.))) # make column names lower case

# Transform 7Q10 response variable
area <- data_full$drain_sqkm
ln7q10_da <- log((data_full$y7q10+0.001)/area)

# use functions from PUBAD to cull covariates
expVars <- data.frame(gages = data_full$staid) %>%
  getBasinChar()

# create model data using clean basin chars
model_data <- expVars$cleanBCs %>% # start with basin chars
  mutate(CLASS = as.integer(as.factor(CLASS))) %>% # change class to integer
  mutate_each(funs(as.numeric)) %>% # make everything numeric
  scale() %>% # convert to z-score: (x-mu)/sigma
  as.data.frame() %>% # make data frame
  setNames(tolower(names(.))) %>% # make sure colname are lower case
  mutate(y=ln7q10_da) %>% # add the transformed response variable from above
  select(y, class,lat_gage:aspect_eastness) # reorder column positions
```

The raw 7Q10s are divided by the drainage area of the basin and log transformed prior to modelling. Because some of the 7Q10's are zero, a small, arbitrary constant of 0.001 was added to each 7Q10 value prior to taking the log transform. This data transformation for the baseline models is slightly different, and is explained in the "Description of train_bl_models" section below. After the data is loaded, the first steps is to find the optimal hyperparameters of for all of the models using random search and bayesian optimization. This process will take over 24 hours for all of the models, and we already provide the optimal values in the "gather_cv_predictions.R" file. The leave-one-out predicted values are included in the "all_preds.csv" file. You can go ahead and jump straight to the performance metrics section in the "main.R" file. 

\vspace{8pt}

```{r,eval=F}
# source fit_metrics function
source("scripts/fit_metrics.R")

# load cross validated predictions
all_preds <- read.csv("data/all_preds.csv")

# calculate model error
model_error <- fit_metrics(all_preds,data_full)
```

The final steps for this truncated version of the analysis is to calcualte variable importance, partial dependence, and make some plots. 

\vspace{8pt}

```{r,eval=F}
# calculate variable importance
source("scripts/var_imp.R")
var_imp_overall <- var_imp(model_data)

# calculate partial dependence
source("scripts/partial_dependence.R")
pdp_data <- partial_dependence(model_data,var_imp_overall)
```

Note that the variable importance and partial dependence don't actually require direct inputs from the other functions above. However, the model selections for the variable importance are based off pieces of the earlier analysis. The very last step is to create plots from the paper:

\vspace{8pt}

```{r,eval=F}
# generate list of  plots
source("scripts/make_plots.R")
plots <- make_plots(all_preds,model_error,var_imp_overall,pdp_data)

# display the plots
plots$rmse_vs_unitrmse
plots$pred_vs_obs
plots$error_decomp
plots$var_imp
plots$partial_dep
```

\newpage

## Extended analysis

This section includes more information about determining the hyperparameters of the models and the monte carlo analysis. 

### Description of train_ml_models()

The process for the machine learning models is conceptually similar to the baseline models, but is much more computationally expensive. This basic pipeline involves (1) generating a bunch of points in hyperparameters and RMSE space to be used as substrate for a gaussian process model, and (2) use bayesian optimization to estimate the functional relationship between the hyperparameters and the RMSE. The gaussian process model attempts to discover a function that relates values of the hyperparameters to an output, in this case, the RMSE. Then an optimization function is used to seek for the combination of parameters where the function is maximized. Theoretically this should result in a set of optimal hyperparameters for a given model. Below is an example using a support vector machine (SVM) model. There are only two hyperparameters for a SVM model, the effect that the large residuals have on the regression is controlled by the \textit{cost (C)} and the standard deviation of the Gaussian kernel is controlled by \textit{sigma}. We don't know what values to select apriori, so we use the steps above. I have automated this process using a custom function that is a wrapper around both the `train` function from the caret package and the `BayesianOptimization` function from the rBayesianOptimization package.

\vspace{8pt}

```{r,eval=F}
library(caret)
source('scripts/bayes_optim_caret.R')

# list of parameter boundaries
svmg_bounds <-  list(C = c(1,5),
                     sigma = c(0,1))

# pass to custom function
svmg_params <- bayes_optim_caret(model_data,'svmRadial',svmg_bounds,iter=10,acq='ucb')
```

```{r,echo=F,eval=F}
seed <- svmg_params$History %>%
  mutate(iter_type = ifelse(Round>10,"bayes opt","random seed")) %>%
  filter(iter_type=="random seed")

opt <- svmg_params$History %>%
  mutate(iter_type = ifelse(Round>10,"bayes opt","random seed")) %>%
  filter(iter_type=="bayes opt") 

ggplot() +
  geom_segment(data=opt,
               aes(x=C,y=sigma,
                   xend=c(tail(C, n=-1), NA),
                   yend=c(tail(sigma, n=-1), NA),
                   #alpha=Round,
                   color=Value),
               arrow=arrow(length=unit(0.2,"cm"))) +
  geom_point(data=seed,aes(x=C,y=sigma,fill=Value),shape=21) +
  scale_alpha(range=c(0.1,0.8),guide=F) +
  theme_bw() +
  scale_fill_viridis() +
  scale_color_viridis(guide=F)
```

We can easily plot the parameter search for the SVM as it only has two parameters. The algorithm first seeds the search space with 10 random RMSE values resulting from different combinations of parameters. These are represented as the colored points below. The value is the negative RMSE in log space. We take the negation of the RMSE because the algorithm seeks to maximize the function. The line segments and the arrows represent the iterations of the Gaussian process model, with the color of the line indicating the resulting -RMSE for each iteration. 

\begin{figure}[ht]
\begin{center}
\includegraphics[width=5in]{~/Documents/Ungaged basins/epa_7q10_ml/figures/svm_search.png}
\end{center}
\end{figure}

\newpage

### Description of train_bl_models()

We classified multivariate regression and geostatistical models as ``baseline'' methods. This classification scheme is used as a way to compare groups of models and does not reflect the complexity, accuracy, or robustness of the method. The models include two versions of censored regression, ordinary kriging, and a unit-area discharge null model. The first thing to note is that the response varaible is slightly different for the censored regression models. 

\vspace{8pt}

```{r, eval=F}
  model_data <- expVars$cleanBCs %>% # start with basin chars
    setNames(tolower(names(.))) %>% # make sure colname are lower case
    mutate(class = as.integer(as.factor(class))) %>% # change class to integer
    mutate(drain_sqkm = log(drain_sqkm)) %>%
    mutate_each(funs(as.numeric)) %>% # make everything numeric
    scale() %>% # convert to z-score: (x-mu)/sigma
    as.data.frame() %>% # make data frame
    mutate(y=data_full$y7q10+0.001) %>%
    mutate(y=log(y)) %>%
    select(y, class:aspect_eastness)
```

If you compare this setup to the `model_data` setup above, you will notice that the response variable is slightly different. This is because the the censored regression functions require a unique censoring value. In raw 7Q10 space, this is normally just zero. If we add a small constant to the 7Q10's and normalize them by their drainage basins, then there is no longer a unique censoring value (because the drainage basin areas are different). Therefore, we just take the natural log of the 7Q10 + 0.001 and censor as ln(0.001). 

The only two models that require tuning are the two versions of the censored regression models. For example, the full censored regression model requires selecting a subset of predictors using best subset selection. It is impossible to know which predictors or the best selection algorithm to select apriori, so this is tunes using cross validation. The first step is to create a grid of possible values:

\vspace{8pt}

```{r, eval=T}
# tune parameter grid for lcr_tobit
  lcr_grid <- expand.grid(subset_method=c("forward","backward"),
                          subset_number=c(2,4,8,10,12))

print(lcr_grid)
```

and in this case, 10 different models are built inside a loo-cv framework and the RMSE is recorded for each model. The model with the lowest RMSE is selected as the final model. This process is referred to a "grid search". 

\vspace{8pt}

```{r, eval=F}
  lcr_tune_error <- numeric()
  for (i in 1:nrow(lcr_grid)){
    
    # fit model with values from grid
    fit <- lcr.tobit(model_data, 
                     subset_method=as.character(lcr_grid[i,1]),
                     subset_number=lcr_grid[i,2], 
                     thold=log(0.001))
    
    # record rmse for ith model
    lcr_tune_error[i] <- sqrt(mean((fit$obs-fit$pred)^2,na.rm=T))
  }
```

A similar process is done for the region of influenced censored regression model, but with an additional "neighbors" hyperparameters.

\vspace{8pt}

```{r, eval=F}
# tune parameter grid for ROI lcr_tobit
  roi_grid <- expand.grid(neighbors=seq(25,200,25),
                          subset_method=c("forward","backward"),
                          subset_number=c(2,4,8,10,12))

  roi_tune_error <- numeric()
  for (i in 1:nrow(roi_grid)){
    
    # fit model with values from grid
    fit <- roi.lcr.tobit(model_data, 
                         neighbors=roi_grid[i,1],
                         subset_method=as.character(roi_grid[i,2]),
                         subset_number=roi_grid[i,3], 
                         thold=log(0.001))
     
    # record rmse for ith model
    roi_tune_error[i] <- sqrt(mean((fit$obs-fit$pred)^2,na.rm=T))
  }
```

